{"authors": ["Rob Waugh Tech Correspondent", "Rob Waugh Tech Correspondent For Dailymail.Com"], "date_download": "2024-02-05 15:16:27", "date_modify": "None", "date_publish": "2024-01-22 14:13:18", "description": "OpenAI, the maker of ChatGPT, has quietly changed its rules and removed a ban on using the chatbot and its other AI tools for military purposes.", "filename": "https%3A%2F%2Fwww.dailymail.co.uk%2Fsciencetech%2Farticle-12978361%2FChatGPT-maker-quietly-changes-rules-allow-military-incorporate-technology.html%3Fns_mchannel%3Drss%26ns_campaign%3D1490%26ito%3D1490.json", "image_url": "https://i.dailymail.co.uk/1s/2024/01/22/14/80194365-0-OpenAI_the_maker_of_ChatGPT_has_quietly_changed_its_rules_and_re-a-2_1705932754687.jpg", "language": "en", "localpath": null, "maintext": "OpenAI, the maker of ChatGPT, has quietly changed its rules and removed a ban on using the chatbot and its other AI tools for military purposes - and revealed that it is already working with the Department of Defense.\nExperts have previously voiced fears that AI could escalate conflicts around the world thanks to 'slaughterbots' which can kill without any human intervention.\nThe rule change, which occurred after Wednesday last week, removed a sentence which said that the company would not permit usage of models for 'activity that has high risk of physical harm, including: weapons development, military and warfare.'\nAn OpenAI spokesperson told DailyMail.com that the company, which is in talks to raise money at a valuation of $100 billion, is working with the Department of Defense on cybersecurity tools built to protect open-source software.\nOpenAI, the maker of ChatGPT , has quietly changed its rules and removed a ban on using the chatbot and its other AI tools for military purposes (stock image)\nThe spokesman said: 'Our policy does not allow our tools to be used to harm people, develop weapons, for communications surveillance, or to injure others or destroy property.\n'There are, however, national security use cases that align with our mission.\n'For example, we are already working with the Defense Advanced Research Projects Agency ( DARPA) to spur the creation of new cybersecurity tools to secure open source software that critical infrastructure and industry depend on.\n'It was not clear whether these beneficial use cases would have been allowed under 'military' in our previous policies. So the goal with our policy update is to provide clarity and the ability to have these discussions.'\nLast year, 60 countries including the U.S. and China signed a 'call to action' to limit the use of artificial intelligence (AI) for military reasons.\nHuman rights experts at the Hague pointed out that the 'call to action' is not legally binding and did not address concerns including lethal AI drones or that AI could escalate existing conflicts.\nSignatories said they were committed to developing and using military AI in accordance with 'international legal obligations and in a way that does not undermine international security, stability and accountability.'\nUkraine has made use of facial recognition and AI-assisted targeting systems in its fight with Russia.\nIn 2020, Libyan government forces launched an autonomous Turkish Kargu-2 drone that attacked retreating rebel soldiers, the first attack of its kind in history, according to a UN report.\nThe lethal drone was programmed to attack 'without requiring data connectivity between the operator and the munition: in effect, a true 'fire, forget and find' capability,' the UN report said.\nAnna Makanju, OpenAI's VP of global affairs, said in an interview this week that the 'blanket' provision was removed to allow for military use cases the company agrees with.\nMakanju told Bloomberg'Because we previously had what was essentially a blanket prohibition on military, many people thought that would prohibit many of these use cases, which people think are very much aligned with what we want to see in the world.'\nSam Altman of OpenAI talks at Davos (Getty)\nThe use of AI for military purposes by 'Big Tech' organisations has previously caused controversy.\nIn 2018, thousands of Google employees protested against a Pentagon contract - Project Maven - which saw the company's AI tools used to analyze drone surveillance footage.\nIn the wake of the protests, Google did not renew the contract.\nMicrosoft employees protested against a $480 million contract to provide soldiers with augmented reality headsets.\nIn 2017, technology leaders including Elon Musk wrote to the UN calling for autonomous weapons to be banned, under laws similar to those that ban chemical weapons and lasers built to blind people.\nThe group warned that autonomous weapons threatened to usher in a 'third revolution in warfare': the first two being gunpowder, and nuclear weapons.\nThe experts warned that once the 'Pandora's box' of fully autonomous weaponry has been opened, it may be impossible to close it again.", "source_domain": "www.dailymail.co.uk", "text": null, "title": "ChatGPT maker quietly changes rules to allow the US military to incorporate its technology", "title_page": null, "title_rss": null, "url": "https://www.dailymail.co.uk/sciencetech/article-12978361/ChatGPT-maker-quietly-changes-rules-allow-military-incorporate-technology.html?ns_mchannel=rss&ns_campaign=1490&ito=1490"}